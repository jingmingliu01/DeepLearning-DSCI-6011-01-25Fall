{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jingmingliu01/DeepLearning-DSCI-6011-01-25Fall/blob/main/Assignment2_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wSats16-sP-"
      },
      "source": [
        "#### Instructions:  \n",
        "1. Libraries allowed: **Python basic libraries, numpy, pandas, scikit-learn (only for data processing), and pytorch.**\n",
        "2. Show all outputs.\n",
        "3. Submit jupyter notebook and a pdf export of the notebook.\n",
        "4. For practice examples, change variable name, shape, mathematical operations, nummerical values, tensor sizes etc. Be creative!\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1kW6okz-sQC"
      },
      "source": [
        "### Data Collection and Pre-processing\n",
        "#### Q1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ye1-LvJ2-sQC"
      },
      "source": [
        "#### a) Tensors\n",
        "Complete the tutorial at https://docs.pytorch.org/tutorials/beginner/basics/tensorqs_tutorial.html . make changes to the tensor, variable name etc. to make your example completely different from tutorial. Failing to do so will earn you zero credit.\n",
        "\n",
        "Add as many cells below as needed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_pqB1y0o-sQD"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.1 Directly from data**"
      ],
      "metadata": {
        "id": "XnSt8kv-ByDR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = [[1,3.14],\n",
        "        [4,5],\n",
        "        [6,7]]"
      ],
      "metadata": {
        "id": "RmzqmRVd_gV0"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i2gMgdPYBFfd",
        "outputId": "8a99d963-2f21-4bef-d014-3dbf6d648ee5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1, 3.14], [4, 5], [6, 7]]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_data = torch.tensor(data)"
      ],
      "metadata": {
        "id": "U0SfJEwEA1xP"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4RkhWAr9A3Jw",
        "outputId": "6ffbf06b-4caa-449c-9d14-7771d884daeb"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.0000, 3.1400],\n",
              "        [4.0000, 5.0000],\n",
              "        [6.0000, 7.0000]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xmuCQ1T3BIwD",
        "outputId": "bd980bfa-8bcc-44f3-bbac-06dfb5cc905d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.2 From a NumPy array**"
      ],
      "metadata": {
        "id": "TLEXkpnQCm3z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np_data = np.array(data)"
      ],
      "metadata": {
        "id": "dApW1bWlCn7L"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8tB7mpf4DLKq",
        "outputId": "944d05f7-15db-4dfa-d762-64b0f25f795d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.  , 3.14],\n",
              "       [4.  , 5.  ],\n",
              "       [6.  , 7.  ]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_np_data=torch.from_numpy(np_data)"
      ],
      "metadata": {
        "id": "uHcT29W8C-sA"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_np_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t7rTX2HvDXXK",
        "outputId": "ec3cd2bd-e481-4829-87ff-cfd07ecc8f6f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.0000, 3.1400],\n",
              "        [4.0000, 5.0000],\n",
              "        [6.0000, 7.0000]], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_np_data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bSbZqFqRDSOt",
        "outputId": "0b324833-7f8a-4494-e4de-6c9c9c675bac"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.3 From another tensor**"
      ],
      "metadata": {
        "id": "zI207b_YDgZ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_ones = torch.ones_like(tensor_data)"
      ],
      "metadata": {
        "id": "fN74yVFYDiJN"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Ones Tensor: \\n {x_ones} \\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3skYYupEFDKz",
        "outputId": "708c2e1a-55af-47b0-c7fe-c54225ee6d42"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ones Tensor: \n",
            " tensor([[1., 1.],\n",
            "        [1., 1.],\n",
            "        [1., 1.]]) \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_rand = torch.rand_like(tensor_data, dtype=torch.float)"
      ],
      "metadata": {
        "id": "MeQ--fr_FMv3"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Random Tensor: \\n {x_rand} \\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fl09jWRAFPMl",
        "outputId": "aa6d71ca-03d0-4a92-95d5-81a90231e936"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Tensor: \n",
            " tensor([[0.7702, 0.7655],\n",
            "        [0.1124, 0.8028],\n",
            "        [0.1585, 0.9980]]) \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.4 With random or constant values**"
      ],
      "metadata": {
        "id": "uclTqIygFxNc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "shape=(4,2) # this is a tuple"
      ],
      "metadata": {
        "id": "iFEdoddEFypw"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rand = torch.rand(shape)\n",
        "ones = torch.ones(shape)\n",
        "zeros = torch.zeros(shape)"
      ],
      "metadata": {
        "id": "OgRtZfGCF-3e"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Random Tensor: \\n {rand} \\n\")\n",
        "print(f\"Ones Tensor: \\n {ones} \\n\")\n",
        "print(f\"Zeros Tensor: \\n {zeros}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ElwRbXxiGC9K",
        "outputId": "47b2eb7a-49a1-4fe4-a257-2218ddf56646"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Tensor: \n",
            " tensor([[0.2552, 0.1375],\n",
            "        [0.3947, 0.0059],\n",
            "        [0.7907, 0.5160],\n",
            "        [0.4814, 0.0043]]) \n",
            "\n",
            "Ones Tensor: \n",
            " tensor([[1., 1.],\n",
            "        [1., 1.],\n",
            "        [1., 1.],\n",
            "        [1., 1.]]) \n",
            "\n",
            "Zeros Tensor: \n",
            " tensor([[0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 0.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.5 Attributes of a Tensor**"
      ],
      "metadata": {
        "id": "hTNX_GZ2GfGd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = torch.rand(2,5)\n",
        "\n",
        "print(f\"Shape of tensor: {tensor.shape}\")\n",
        "print(f\"Datatype of tensor: {tensor.dtype}\")\n",
        "print(f\"Device tensor is stored on: {tensor.device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TcdqJoYNGdvf",
        "outputId": "36f055db-db97-4dd8-e567-8ceabd9adbc7"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of tensor: torch.Size([2, 5])\n",
            "Datatype of tensor: torch.float32\n",
            "Device tensor is stored on: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2 Operations on Tensors**"
      ],
      "metadata": {
        "id": "DtVFSbyrK3Bs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We move our tensor to the current accelerator if available\n",
        "if torch.accelerator.is_available():\n",
        "    tensor = tensor.to(torch.accelerator.current_accelerator())"
      ],
      "metadata": {
        "id": "LEvFtd0VNZlz"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.1 Standard numpy-like indexing and slicing:**"
      ],
      "metadata": {
        "id": "ofrv9rVzK4_M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = torch.ones(3, 3)\n",
        "print(f\"First row: {tensor[0]}\")\n",
        "print(f\"First column: {tensor[:, 0]}\")\n",
        "print(f\"Last column: {tensor[..., -1]}\")\n",
        "tensor[:,2] = 0\n",
        "print(tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rm-f6oVoK2qx",
        "outputId": "90b9e174-7727-4d3b-853e-9661e203480e"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First row: tensor([1., 1., 1.])\n",
            "First column: tensor([1., 1., 1.])\n",
            "Last column: tensor([1., 1., 1.])\n",
            "tensor([[1., 1., 0.],\n",
            "        [1., 1., 0.],\n",
            "        [1., 1., 0.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Joining tensors**"
      ],
      "metadata": {
        "id": "UpnsAoRTPEny"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t1 = torch.cat([tensor, tensor, tensor], dim=1)\n",
        "print(t1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6XEaBhL9PF5T",
        "outputId": "144d6d45-c016-407f-c616-07a6ce8c61b3"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 1., 0., 1., 1., 0., 1., 1., 0.],\n",
            "        [1., 1., 0., 1., 1., 0., 1., 1., 0.],\n",
            "        [1., 1., 0., 1., 1., 0., 1., 1., 0.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t2 = torch.cat([tensor, tensor, tensor], dim=0)\n",
        "print(t2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q6HlZ6IQQAqP",
        "outputId": "3284f942-fe58-4b4e-a5d4-ce2cf27131db"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 1., 0.],\n",
            "        [1., 1., 0.],\n",
            "        [1., 1., 0.],\n",
            "        [1., 1., 0.],\n",
            "        [1., 1., 0.],\n",
            "        [1., 1., 0.],\n",
            "        [1., 1., 0.],\n",
            "        [1., 1., 0.],\n",
            "        [1., 1., 0.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Arithmetic operations**"
      ],
      "metadata": {
        "id": "zXPvka-YQIZV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This computes the matrix multiplication between two tensors. y1, y2, y3 will have the same value\n",
        "# ``tensor.T`` returns the transpose of a tensor\n",
        "y1 = tensor @ tensor.T\n",
        "y2 = tensor.matmul(tensor.T)\n",
        "\n",
        "y3 = torch.rand_like(y1)\n",
        "torch.matmul(tensor, tensor.T, out=y3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FwgIJDNDQJVv",
        "outputId": "3f53dc51-ba83-4fa6-d8c3-88c53a46cecf"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2., 2., 2.],\n",
              "        [2., 2., 2.],\n",
              "        [2., 2., 2.]])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79HrjVkAUgrg",
        "outputId": "ecb1a812-43ba-4f3d-b79b-62aaf9045276"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2., 2., 2.],\n",
              "        [2., 2., 2.],\n",
              "        [2., 2., 2.]])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9BuLiXL6Uh1w",
        "outputId": "91340e71-e9b7-47ae-c3db-b4dbebf01204"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2., 2., 2.],\n",
              "        [2., 2., 2.],\n",
              "        [2., 2., 2.]])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x_dGwAYUUibB",
        "outputId": "e9b99b32-f240-494a-9390-86e66975a65c"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2., 2., 2.],\n",
              "        [2., 2., 2.],\n",
              "        [2., 2., 2.]])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This computes the element-wise product. z1, z2, z3 will have the same value\n",
        "z1 = tensor * tensor\n",
        "z2 = tensor.mul(tensor)\n",
        "\n",
        "z3 = torch.rand_like(tensor)\n",
        "torch.mul(tensor, tensor, out=z3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ll0XkqNU2To",
        "outputId": "28c75a18-d321-4731-e88d-9940b3f9037e"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 0.],\n",
              "        [1., 1., 0.],\n",
              "        [1., 1., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Single-element tensors**"
      ],
      "metadata": {
        "id": "XdMshTNPVzV9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "agg = tensor.sum()\n",
        "agg_item = agg.item()\n",
        "print(agg_item, type(agg_item))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iNGzf5sSVzpv",
        "outputId": "8bfed07f-5b93-4785-d913-27f64daf128d"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6.0 <class 'float'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**In-place operations**"
      ],
      "metadata": {
        "id": "RArixVOmV5ng"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = torch.ones(3,3)\n",
        "print(f\"{tensor} \\n\")\n",
        "tensor.add_(3)\n",
        "print(tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8bH3zXtxV9hh",
        "outputId": "3233bfae-282e-44b2-c680-5f539b43eade"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.]]) \n",
            "\n",
            "tensor([[4., 4., 4.],\n",
            "        [4., 4., 4.],\n",
            "        [4., 4., 4.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3 Bridge with NumPy**"
      ],
      "metadata": {
        "id": "gsh3xp6eWm0h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.1 Tensor to NumPy array**"
      ],
      "metadata": {
        "id": "X2BcepljdvhA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t = torch.ones(3)\n",
        "print(f\"t: {t}\")\n",
        "n = t.numpy()\n",
        "print(f\"n: {n}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aH96QFuHWoMV",
        "outputId": "b8cb955a-05ae-442d-d183-140a1621572e"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "t: tensor([1., 1., 1.])\n",
            "n: [1. 1. 1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t.add_(1)\n",
        "print(f\"t: {t}\")\n",
        "print(f\"n: {n}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iE3g0h43LSpt",
        "outputId": "5cc88558-2bfe-4c67-f818-b9f3182900f6"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "t: tensor([2., 2., 2.])\n",
            "n: [2. 2. 2.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n = np.ones(5)\n",
        "t = torch.from_numpy(n)"
      ],
      "metadata": {
        "id": "UmQweGy8LUGq"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.add(n, 1, out=n)\n",
        "print(f\"t: {t}\")\n",
        "print(f\"n: {n}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "owl-A23kLdW2",
        "outputId": "1f16037a-f25c-42ad-f916-21d169524011"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "t: tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n",
            "n: [2. 2. 2. 2. 2.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NzvrRVvd-sQD"
      },
      "source": [
        "#### b) Autormatic differentiation\n",
        "Complete the tutorial at https://pytorch.org/tutorials/beginner/basics/autogradqs_tutorial.html . Again, make changes to the tensor, variable name etc. to make your example completely different from tutorial. Failing to do so will earn you zero credit.\n",
        "\n",
        "Add as many cells below as needed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "Fl-YYzVw-sQD"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "x = torch.ones(6)  # input tensor\n",
        "y = torch.zeros(2)  # expected output\n",
        "w = torch.randn(6, 2, requires_grad=True)\n",
        "b = torch.randn(2, requires_grad=True)\n",
        "z = x @ w +b\n",
        "loss = torch.nn.functional.binary_cross_entropy_with_logits(z, y)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Gradient function for z = {z.grad_fn}\")\n",
        "print(f\"Gradient function for loss = {loss.grad_fn}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eDaLJtPyQkXS",
        "outputId": "6066af6a-eb48-4fee-872f-a8f09c438123"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradient function for z = <AddBackward0 object at 0x78eea2820910>\n",
            "Gradient function for loss = <BinaryCrossEntropyWithLogitsBackward0 object at 0x78eea324b490>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss.backward()\n",
        "print(w.grad)\n",
        "print(b.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0HVW9Y8GQ8kw",
        "outputId": "09cb6e6c-a886-4f6a-a4a9-6eba4dd09d46"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.4262, 0.1864],\n",
            "        [0.4262, 0.1864],\n",
            "        [0.4262, 0.1864],\n",
            "        [0.4262, 0.1864],\n",
            "        [0.4262, 0.1864],\n",
            "        [0.4262, 0.1864]])\n",
            "tensor([0.4262, 0.1864])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Disabling Gradient Tracking**"
      ],
      "metadata": {
        "id": "cWW7N7BoRiWC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "z = torch.matmul(x, w)+b\n",
        "print(z.requires_grad)\n",
        "\n",
        "with torch.no_grad():\n",
        "    z = torch.matmul(x, w)+b\n",
        "print(z.requires_grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RJ19zxvrRhqB",
        "outputId": "7674b03e-e140-448b-d951-a433bea759bd"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z = torch.matmul(x, w)+b\n",
        "z_det = z.detach()\n",
        "print(z_det.requires_grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "anJHWL3IRwgB",
        "outputId": "111b9a4f-d778-473f-9f36-568e72dc5011"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Jacobian Product**"
      ],
      "metadata": {
        "id": "lZyrAb_TwjLo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inp = torch.eye(4, 5, requires_grad=True)"
      ],
      "metadata": {
        "id": "mGeVGog1p3qm"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_mwkE1nwteO",
        "outputId": "cdd31a1f-4102-44a6-beb5-9b9fe235a3a9"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 0., 0., 0., 0.],\n",
              "        [0., 1., 0., 0., 0.],\n",
              "        [0., 0., 1., 0., 0.],\n",
              "        [0., 0., 0., 1., 0.]], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out = (inp+1).pow(2).t()"
      ],
      "metadata": {
        "id": "AtioQ5qDwhQv"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fn8La8Guwwm-",
        "outputId": "f793c9a0-1f82-4230-8a2c-ac5e011d8343"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[4., 1., 1., 1.],\n",
              "        [1., 4., 1., 1.],\n",
              "        [1., 1., 4., 1.],\n",
              "        [1., 1., 1., 4.],\n",
              "        [1., 1., 1., 1.]], grad_fn=<TBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out.backward(torch.ones_like(out), retain_graph=True)\n",
        "print(f\"First call\\n{inp.grad}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZGZQOoKewiaq",
        "outputId": "5fa3b291-5a42-41e8-e769-73a215d38673"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First call\n",
            "tensor([[4., 2., 2., 2., 2.],\n",
            "        [2., 4., 2., 2., 2.],\n",
            "        [2., 2., 4., 2., 2.],\n",
            "        [2., 2., 2., 4., 2.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out.backward(torch.ones_like(out), retain_graph=True)\n",
        "print(f\"\\nSecond call\\n{inp.grad}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9s3pnNGXwp88",
        "outputId": "1325e778-51b1-4e67-eeda-8e0226f4d36e"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Second call\n",
            "tensor([[8., 4., 4., 4., 4.],\n",
            "        [4., 8., 4., 4., 4.],\n",
            "        [4., 4., 8., 4., 4.],\n",
            "        [4., 4., 4., 8., 4.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inp.grad.zero_()\n",
        "out.backward(torch.ones_like(out), retain_graph=True)\n",
        "print(f\"\\nCall after zeroing gradients\\n{inp.grad}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Bu7QoUNwq9R",
        "outputId": "db863652-b33c-4d73-c19c-2ff442837f66"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Call after zeroing gradients\n",
            "tensor([[4., 2., 2., 2., 2.],\n",
            "        [2., 4., 2., 2., 2.],\n",
            "        [2., 2., 4., 2., 2.],\n",
            "        [2., 2., 2., 4., 2.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQPC5P8n-sQD"
      },
      "source": [
        "#### c) Datasets and Dataloader\n",
        "\n",
        "Download the \"Hand Keypoint detection\" dataset from https://www.kaggle.com/datasets/pablocumbrera/hand-keypoint-detection .\n",
        "1. Define a pytorch Dataset class, HandKpDetection.\n",
        "   1. Implement ``__init__`` method, in which gather the filepaths to all images in the dataset and store them in a list. Don't load the entire dataset or images in this method. Both image and label file share the same prefix, so just storing filepath for images will work.\n",
        "   2. implement ``__len__`` method.\n",
        "   3. Implement ``__getitem__(self, index)`` where you will load just one sample corresponding to the ``index`` in the method argument. Use the filepath information in the init methods to load both image and keypoints. Reshape the image to $32\\times 32$ and keypoints to $20\\times 2$\n",
        "2. Implement Dataloaders with a minibatch size of 2. Convert both image and keypoints to ``torch.tensor``.\n",
        "3. Visualize the images and print the keypoints in the first minibatch\n",
        "\n",
        "Add as many cells below as needed."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Download the dataset**"
      ],
      "metadata": {
        "id": "ooAUrNUQJyR6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GJB4D5cW-sQE",
        "outputId": "255ff5d4-e0fb-4251-ec10-3f9813b71ded"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/pablocumbrera/hand-keypoint-detection?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 632M/632M [00:04<00:00, 154MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n",
            "Path to dataset files: /root/.cache/kagglehub/datasets/pablocumbrera/hand-keypoint-detection/versions/1\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"pablocumbrera/hand-keypoint-detection\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define a pytorch Dataset class, HandKpDetection**"
      ],
      "metadata": {
        "id": "L_miBbiBJ2JU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, glob, json\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "e_CApMiB9WsP"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class HandKpDetection(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            root_dir (str): Dataset root, e.g.\n",
        "                '/root/.cache/kagglehub/datasets/pablocumbrera/hand-keypoint-detection/versions/1/hand_labels_synth'\n",
        "            transform: optional torchvision transform for images\n",
        "        \"\"\"\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "\n",
        "        # collect all .jpg files under synth1..synth4\n",
        "        self.image_paths = []\n",
        "        for folder in [\"synth1\", \"synth2\", \"synth3\", \"synth4\"]:\n",
        "            self.image_paths.extend(sorted(glob.glob(os.path.join(root_dir, folder, \"*.jpg\"))))\n",
        "\n",
        "        print(\"Found\", len(self.image_paths), \"images\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "      # --- load image ---\n",
        "      img_path = self.image_paths[index]\n",
        "      image = Image.open(img_path).convert(\"RGB\")\n",
        "      orig_w, orig_h = image.size   # original size\n",
        "\n",
        "      # resize\n",
        "      image = image.resize((32, 32))\n",
        "      new_w, new_h = 32, 32\n",
        "\n",
        "      # convert to tensor\n",
        "      image = np.array(image, dtype=np.float32) / 255.0\n",
        "      image = np.transpose(image, (2, 0, 1))\n",
        "      image = torch.tensor(image)\n",
        "\n",
        "      # --- load keypoints ---\n",
        "      json_path = img_path.replace(\".jpg\", \".json\")\n",
        "      with open(json_path, \"r\") as f:\n",
        "          ann = json.load(f)\n",
        "      keypoints = np.array(ann[\"hand_pts\"], dtype=np.float32)[:, :2]\n",
        "      keypoints = keypoints.reshape(-1, 2)[:20]\n",
        "\n",
        "      # scale keypoints to new size\n",
        "      scale_x = new_w / orig_w\n",
        "      scale_y = new_h / orig_h\n",
        "      keypoints[:, 0] *= scale_x\n",
        "      keypoints[:, 1] *= scale_y\n",
        "\n",
        "      keypoints = torch.tensor(keypoints)\n",
        "\n",
        "      return image, keypoints\n"
      ],
      "metadata": {
        "id": "wRk8ojUx6veB"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Implement Dataloaders with a minibatch size of 2. Convert both image and keypoints to torch.tensor.**"
      ],
      "metadata": {
        "id": "Z44QQElOJ4uL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "root = \"/root/.cache/kagglehub/datasets/pablocumbrera/hand-keypoint-detection/versions/1/hand_labels_synth\"\n",
        "dataset = HandKpDetection(root)\n",
        "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)\n",
        "\n",
        "images, keypoints = next(iter(dataloader))\n",
        "print(\"Batch images:\", images.shape)      # [2, 3, 32, 32]  [batch_size, channels, shape_x, shape_y]\n",
        "print(\"Batch keypoints:\", keypoints.shape) # [2, 20, 2]     [batch_size, shape_x, shape_y]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SxMNMNKV91D_",
        "outputId": "69fc3869-2995-4e0a-9e9d-155bb93d59d6"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 14261 images\n",
            "Batch images: torch.Size([2, 3, 32, 32])\n",
            "Batch keypoints: torch.Size([2, 20, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Visualize the images and print the keypoints in the first minibatch**"
      ],
      "metadata": {
        "id": "vlSwTGW7KMvc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# get the first minibatch\n",
        "images, keypoints = next(iter(dataloader))\n",
        "\n",
        "print(\"First minibatch keypoints (tensor):\")\n",
        "print(keypoints)\n",
        "\n",
        "# visualize both images in the minibatch\n",
        "fig, axes = plt.subplots(1, 2, figsize=(6, 3))\n",
        "\n",
        "for i in range(2):  # because batch_size = 2\n",
        "    img = images[i].permute(1, 2, 0).numpy()   # CHW -> HWC\n",
        "    kp = keypoints[i].numpy()\n",
        "\n",
        "    axes[i].imshow(img)\n",
        "    axes[i].scatter(kp[:, 0], kp[:, 1], c='red', s=10)  # plot keypoints\n",
        "    axes[i].set_title(f\"Sample {i}\")\n",
        "    axes[i].axis(\"off\")\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "TRN-h3LMJuNw",
        "outputId": "a4ab6144-0df9-48d9-e0d1-a6875086d088"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First minibatch keypoints (tensor):\n",
            "tensor([[[15.2862, 13.7748],\n",
            "         [16.5025, 14.4271],\n",
            "         [17.8023, 15.0550],\n",
            "         [18.5364, 15.7991],\n",
            "         [ 0.0000,  0.0000],\n",
            "         [16.7636, 15.2475],\n",
            "         [16.8107, 16.3507],\n",
            "         [16.8385, 17.3640],\n",
            "         [ 0.0000,  0.0000],\n",
            "         [15.8861, 15.3574],\n",
            "         [16.0766, 16.5415],\n",
            "         [16.2135, 17.6143],\n",
            "         [ 0.0000,  0.0000],\n",
            "         [15.1119, 15.4600],\n",
            "         [15.4075, 16.5340],\n",
            "         [15.6191, 17.5492],\n",
            "         [ 0.0000,  0.0000],\n",
            "         [14.2789, 15.5900],\n",
            "         [14.7824, 16.7960],\n",
            "         [14.9611, 17.3822]],\n",
            "\n",
            "        [[27.7151, 22.7477],\n",
            "         [24.2869, 18.2412],\n",
            "         [23.6683, 14.2494],\n",
            "         [18.8085, 12.6842],\n",
            "         [15.3154, 14.6120],\n",
            "         [21.0979, 10.7489],\n",
            "         [15.5009, 11.9443],\n",
            "         [16.4958, 15.4813],\n",
            "         [20.1234, 16.1749],\n",
            "         [19.8924, 12.9190],\n",
            "         [12.4585, 13.9200],\n",
            "         [12.6645, 17.3419],\n",
            "         [16.9662, 18.1855],\n",
            "         [18.7001, 15.1315],\n",
            "         [11.6058, 13.7552],\n",
            "         [ 9.2715, 15.6757],\n",
            "         [10.5937, 18.0321],\n",
            "         [17.9553, 17.8488],\n",
            "         [13.1157, 19.2567],\n",
            "         [11.4207, 21.1962]]])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x300 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mroxfk8H-sQE"
      },
      "source": [
        "#### d) Build model\n",
        "Complete the tutorial at https://pytorch.org/tutorials/beginner/basics/buildmodel_tutorial.html.\n",
        "\n",
        "Add as many cells below as needed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "t65S1yL--sQE"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1 Get Device for Training**"
      ],
      "metadata": {
        "id": "J4x5iTU3FXw6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bMaiw83PFY0F",
        "outputId": "f121bd87-c4b7-4cc6-d14b-1faf7b0448bc"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.1 Define the Class**"
      ],
      "metadata": {
        "id": "FQ6Pij9RGG6g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(28*28, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 10),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits"
      ],
      "metadata": {
        "id": "J4Zx2KcTGH5g"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = NeuralNetwork().to(device)\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJUPtaz1H-wB",
        "outputId": "0478a93e-fab2-4680-a9ff-cbe78cc23ad0"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.rand(1, 28, 28, device=device)\n",
        "logits = model(X)\n",
        "pred_probab = nn.Softmax(dim=1)(logits)\n",
        "y_pred = pred_probab.argmax(1)\n",
        "print(f\"Predicted class: {y_pred}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ECJSzTY_I8Sl",
        "outputId": "114b224c-e5c7-4814-c4be-6f3dd5dd5690"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted class: tensor([5])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2 Model Layers**"
      ],
      "metadata": {
        "id": "WJAKertFJyHH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_image = torch.rand(3,28,28)\n",
        "print(input_image.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j4uUQxayJzQT",
        "outputId": "7cd753a3-bb92-4414-c4f6-4085c42d8e31"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 28, 28])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.1 nn.Flatten**"
      ],
      "metadata": {
        "id": "QG4y6eRGKBNi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "flatten = nn.Flatten()\n",
        "flat_image = flatten(input_image)\n",
        "print(flat_image.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BpraTb28J-Z2",
        "outputId": "c61ba901-41b6-439e-fd26-ae05c44e5b2c"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 784])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.2 nn.Linear**"
      ],
      "metadata": {
        "id": "9HUQOvYlKcFF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "layer1 = nn.Linear(in_features=28*28, out_features=20)\n",
        "hidden1 = layer1(flat_image)\n",
        "print(hidden1.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJRxFx07KeBi",
        "outputId": "9468d7f0-1a25-4550-b0ab-9feeed63430e"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 20])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.3 nn.ReLU**"
      ],
      "metadata": {
        "id": "rEfSq3zMLXRW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Before ReLU: {hidden1}\\n\\n\")\n",
        "hidden1 = nn.ReLU()(hidden1)\n",
        "print(f\"After ReLU: {hidden1}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qc5JXeSfK2N_",
        "outputId": "6036dd2d-112d-46f7-9ea1-bb9033c9dc3c"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before ReLU: tensor([[ 0.4120,  0.1090,  0.3217,  0.6498,  0.0514, -0.1481, -0.2099, -0.1682,\n",
            "          0.1685,  0.5080, -0.3803, -0.2483,  0.1397, -0.2026,  0.5672, -0.0646,\n",
            "          0.5508,  0.4268,  0.2526,  0.0836],\n",
            "        [ 0.4570,  0.0408,  0.3579,  0.3994,  0.2799,  0.1412, -0.2049, -0.3208,\n",
            "          0.2147,  0.2715, -0.3543,  0.1022,  0.2976, -0.0227,  0.3972, -0.2048,\n",
            "          0.5589,  0.7151,  0.3847, -0.3243],\n",
            "        [ 0.1550,  0.0369,  0.1152,  0.2209,  0.0533,  0.2396,  0.2607, -0.1804,\n",
            "          0.0997,  0.1888, -0.3111, -0.2393,  0.0185, -0.4501,  0.3856, -0.1492,\n",
            "          0.9775,  0.7084,  0.2112,  0.0883]], grad_fn=<AddmmBackward0>)\n",
            "\n",
            "\n",
            "After ReLU: tensor([[0.4120, 0.1090, 0.3217, 0.6498, 0.0514, 0.0000, 0.0000, 0.0000, 0.1685,\n",
            "         0.5080, 0.0000, 0.0000, 0.1397, 0.0000, 0.5672, 0.0000, 0.5508, 0.4268,\n",
            "         0.2526, 0.0836],\n",
            "        [0.4570, 0.0408, 0.3579, 0.3994, 0.2799, 0.1412, 0.0000, 0.0000, 0.2147,\n",
            "         0.2715, 0.0000, 0.1022, 0.2976, 0.0000, 0.3972, 0.0000, 0.5589, 0.7151,\n",
            "         0.3847, 0.0000],\n",
            "        [0.1550, 0.0369, 0.1152, 0.2209, 0.0533, 0.2396, 0.2607, 0.0000, 0.0997,\n",
            "         0.1888, 0.0000, 0.0000, 0.0185, 0.0000, 0.3856, 0.0000, 0.9775, 0.7084,\n",
            "         0.2112, 0.0883]], grad_fn=<ReluBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.4 nn.Sequential**"
      ],
      "metadata": {
        "id": "9ZaBQY_ajEVP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seq_modules = nn.Sequential(\n",
        "    flatten,\n",
        "    layer1,\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(20, 10)\n",
        ")\n",
        "input_image = torch.rand(3,28,28)\n",
        "logits = seq_modules(input_image)"
      ],
      "metadata": {
        "id": "rI0Aq1N1jGUF"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.5 nn.Softmax**"
      ],
      "metadata": {
        "id": "1RKmreyukRj8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "softmax = nn.Softmax(dim=1)\n",
        "pred_probab = softmax(logits)"
      ],
      "metadata": {
        "id": "XoH5N1eEkTEm"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3 Model Parameters**"
      ],
      "metadata": {
        "id": "TKf1tyNlkhI8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Model structure: {model}\\n\\n\")\n",
        "\n",
        "for name, param in model.named_parameters():\n",
        "    print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gNBjNv46kjO0",
        "outputId": "a133e5ec-91c4-4d7c-8d17-09527d345b2b"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model structure: NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "\n",
            "\n",
            "Layer: linear_relu_stack.0.weight | Size: torch.Size([512, 784]) | Values : tensor([[-0.0056, -0.0205, -0.0161,  ...,  0.0045, -0.0124,  0.0135],\n",
            "        [-0.0218,  0.0271, -0.0139,  ...,  0.0201,  0.0002, -0.0295]],\n",
            "       grad_fn=<SliceBackward0>) \n",
            "\n",
            "Layer: linear_relu_stack.0.bias | Size: torch.Size([512]) | Values : tensor([ 0.0233, -0.0174], grad_fn=<SliceBackward0>) \n",
            "\n",
            "Layer: linear_relu_stack.2.weight | Size: torch.Size([512, 512]) | Values : tensor([[-0.0417,  0.0148,  0.0376,  ..., -0.0021, -0.0271, -0.0342],\n",
            "        [ 0.0228,  0.0169, -0.0341,  ...,  0.0015,  0.0166,  0.0191]],\n",
            "       grad_fn=<SliceBackward0>) \n",
            "\n",
            "Layer: linear_relu_stack.2.bias | Size: torch.Size([512]) | Values : tensor([ 0.0288, -0.0011], grad_fn=<SliceBackward0>) \n",
            "\n",
            "Layer: linear_relu_stack.4.weight | Size: torch.Size([10, 512]) | Values : tensor([[-0.0196,  0.0141, -0.0236,  ...,  0.0003,  0.0380,  0.0213],\n",
            "        [ 0.0201,  0.0274, -0.0346,  ...,  0.0156, -0.0084, -0.0153]],\n",
            "       grad_fn=<SliceBackward0>) \n",
            "\n",
            "Layer: linear_relu_stack.4.bias | Size: torch.Size([10]) | Values : tensor([-0.0318,  0.0280], grad_fn=<SliceBackward0>) \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4LTeAco7-sQE"
      },
      "source": [
        "#### e) Optimization loop\n",
        "Complete the tutorial at https://pytorch.org/tutorials/beginner/basics/optimization_tutorial.html.\n",
        "\n",
        "Add as many cells below as needed."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Prerequisite Code**"
      ],
      "metadata": {
        "id": "IhdkHU6DBmDL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "EbSkuBqN-sQF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b36a9948-7f1d-4fcf-f77c-3f1ccbcb570a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26.4M/26.4M [00:03<00:00, 7.19MB/s]\n",
            "100%|██████████| 29.5k/29.5k [00:00<00:00, 233kB/s]\n",
            "100%|██████████| 4.42M/4.42M [00:01<00:00, 4.27MB/s]\n",
            "100%|██████████| 5.15k/5.15k [00:00<00:00, 10.4MB/s]\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "training_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")\n",
        "\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")\n",
        "\n",
        "train_dataloader = DataLoader(training_data, batch_size=64)\n",
        "test_dataloader = DataLoader(test_data, batch_size=64)\n",
        "\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(28*28, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 10),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits\n",
        "\n",
        "model = NeuralNetwork()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hyperparameters**"
      ],
      "metadata": {
        "id": "evw-J0_qBnid"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We define the following hyperparameters for training:\n",
        "\n",
        "**Number of Epochs** - the number of times to iterate over the dataset\n",
        "\n",
        "**Batch Size**- the number of data samples propagated through the network before the parameters are updated\n",
        "\n",
        "**Learning Rate** - how much to update models parameters at each batch/epoch. Smaller values yield slow learning speed, while large values may result in unpredictable behavior during training.\n",
        "\n"
      ],
      "metadata": {
        "id": "GrrS5hxdCais"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 1e-3\n",
        "batch_size = 64\n",
        "epochs = 5"
      ],
      "metadata": {
        "id": "jUAyVYw7BjuR"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Optimization Loop**\n",
        "\n",
        "Each epoch consists of two main parts:\n",
        "The Train Loop - iterate over the training dataset and try to converge to optimal parameters.\n",
        "\n",
        "The Validation/Test Loop - iterate over the test dataset to check if model performance is improving."
      ],
      "metadata": {
        "id": "vN6z99guC0Dm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loss Function**"
      ],
      "metadata": {
        "id": "OEOpi6OrCxTZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the loss function\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "tSf2DTLcDEeE"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Optimizer**"
      ],
      "metadata": {
        "id": "RKku-m0JEMHr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "uUdUJKrVEM0o"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Full Implementation**"
      ],
      "metadata": {
        "id": "Fjnj5idjE2q3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_loop(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    # Set the model to training mode - important for batch normalization and dropout layers\n",
        "    # Unnecessary in this situation but added for best practices\n",
        "    model.train()\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        # Compute prediction and loss\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # Backpropagation\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), batch * batch_size + len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "\n",
        "def test_loop(dataloader, model, loss_fn):\n",
        "    # Set the model to evaluation mode - important for batch normalization and dropout layers\n",
        "    # Unnecessary in this situation but added for best practices\n",
        "    model.eval()\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    test_loss, correct = 0, 0\n",
        "\n",
        "    # Evaluating the model with torch.no_grad() ensures that no gradients are computed during test mode\n",
        "    # also serves to reduce unnecessary gradient computations and memory usage for tensors with requires_grad=True\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
      ],
      "metadata": {
        "id": "g2xdWzSEE3XH"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "epochs = 10\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
        "    test_loop(test_dataloader, model, loss_fn)\n",
        "print(\"Done!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EWUXzCepE5Bv",
        "outputId": "3c6b550d-713c-412b-cb72-a69b652440a3"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 2.308622  [   64/60000]\n",
            "loss: 2.290988  [ 6464/60000]\n",
            "loss: 2.271333  [12864/60000]\n",
            "loss: 2.265017  [19264/60000]\n",
            "loss: 2.245721  [25664/60000]\n",
            "loss: 2.229995  [32064/60000]\n",
            "loss: 2.230161  [38464/60000]\n",
            "loss: 2.207123  [44864/60000]\n",
            "loss: 2.197040  [51264/60000]\n",
            "loss: 2.169623  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 47.9%, Avg loss: 2.162924 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 2.177693  [   64/60000]\n",
            "loss: 2.169887  [ 6464/60000]\n",
            "loss: 2.109456  [12864/60000]\n",
            "loss: 2.123097  [19264/60000]\n",
            "loss: 2.086841  [25664/60000]\n",
            "loss: 2.026262  [32064/60000]\n",
            "loss: 2.048617  [38464/60000]\n",
            "loss: 1.981367  [44864/60000]\n",
            "loss: 1.981413  [51264/60000]\n",
            "loss: 1.908355  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 56.0%, Avg loss: 1.908405 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 1.944233  [   64/60000]\n",
            "loss: 1.920965  [ 6464/60000]\n",
            "loss: 1.795443  [12864/60000]\n",
            "loss: 1.833873  [19264/60000]\n",
            "loss: 1.739199  [25664/60000]\n",
            "loss: 1.675555  [32064/60000]\n",
            "loss: 1.691882  [38464/60000]\n",
            "loss: 1.593845  [44864/60000]\n",
            "loss: 1.614733  [51264/60000]\n",
            "loss: 1.504018  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 58.9%, Avg loss: 1.527136 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 1.595046  [   64/60000]\n",
            "loss: 1.565867  [ 6464/60000]\n",
            "loss: 1.403391  [12864/60000]\n",
            "loss: 1.479101  [19264/60000]\n",
            "loss: 1.366183  [25664/60000]\n",
            "loss: 1.351097  [32064/60000]\n",
            "loss: 1.359906  [38464/60000]\n",
            "loss: 1.281658  [44864/60000]\n",
            "loss: 1.315342  [51264/60000]\n",
            "loss: 1.214487  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 62.4%, Avg loss: 1.247433 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 1.324115  [   64/60000]\n",
            "loss: 1.312121  [ 6464/60000]\n",
            "loss: 1.134184  [12864/60000]\n",
            "loss: 1.248713  [19264/60000]\n",
            "loss: 1.126320  [25664/60000]\n",
            "loss: 1.148835  [32064/60000]\n",
            "loss: 1.163794  [38464/60000]\n",
            "loss: 1.096142  [44864/60000]\n",
            "loss: 1.134020  [51264/60000]\n",
            "loss: 1.054838  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 64.3%, Avg loss: 1.080168 \n",
            "\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "loss: 1.148899  [   64/60000]\n",
            "loss: 1.158048  [ 6464/60000]\n",
            "loss: 0.961657  [12864/60000]\n",
            "loss: 1.109696  [19264/60000]\n",
            "loss: 0.982208  [25664/60000]\n",
            "loss: 1.016265  [32064/60000]\n",
            "loss: 1.045447  [38464/60000]\n",
            "loss: 0.981741  [44864/60000]\n",
            "loss: 1.018878  [51264/60000]\n",
            "loss: 0.957887  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 65.9%, Avg loss: 0.974505 \n",
            "\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "loss: 1.030008  [   64/60000]\n",
            "loss: 1.059564  [ 6464/60000]\n",
            "loss: 0.845693  [12864/60000]\n",
            "loss: 1.018357  [19264/60000]\n",
            "loss: 0.891632  [25664/60000]\n",
            "loss: 0.923935  [32064/60000]\n",
            "loss: 0.968046  [38464/60000]\n",
            "loss: 0.908947  [44864/60000]\n",
            "loss: 0.941274  [51264/60000]\n",
            "loss: 0.892995  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 67.5%, Avg loss: 0.903355 \n",
            "\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 0.943607  [   64/60000]\n",
            "loss: 0.991165  [ 6464/60000]\n",
            "loss: 0.763396  [12864/60000]\n",
            "loss: 0.954127  [19264/60000]\n",
            "loss: 0.831023  [25664/60000]\n",
            "loss: 0.856583  [32064/60000]\n",
            "loss: 0.913476  [38464/60000]\n",
            "loss: 0.860896  [44864/60000]\n",
            "loss: 0.886139  [51264/60000]\n",
            "loss: 0.846017  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 68.8%, Avg loss: 0.852390 \n",
            "\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 0.877411  [   64/60000]\n",
            "loss: 0.939728  [ 6464/60000]\n",
            "loss: 0.702217  [12864/60000]\n",
            "loss: 0.906242  [19264/60000]\n",
            "loss: 0.787717  [25664/60000]\n",
            "loss: 0.805891  [32064/60000]\n",
            "loss: 0.871776  [38464/60000]\n",
            "loss: 0.827430  [44864/60000]\n",
            "loss: 0.845119  [51264/60000]\n",
            "loss: 0.809829  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 69.9%, Avg loss: 0.813761 \n",
            "\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss: 0.824489  [   64/60000]\n",
            "loss: 0.898294  [ 6464/60000]\n",
            "loss: 0.654898  [12864/60000]\n",
            "loss: 0.869168  [19264/60000]\n",
            "loss: 0.755005  [25664/60000]\n",
            "loss: 0.766941  [32064/60000]\n",
            "loss: 0.837797  [38464/60000]\n",
            "loss: 0.802772  [44864/60000]\n",
            "loss: 0.813184  [51264/60000]\n",
            "loss: 0.780600  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 71.2%, Avg loss: 0.783014 \n",
            "\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QWKoy50_-sQF"
      },
      "source": [
        "#### f) Save, load, and use model\n",
        "Complete the tutorial at https://pytorch.org/tutorials/beginner/basics/saveloadrun_tutorial.html.\n",
        "\n",
        "Add as many cells below as needed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "ldWeI4Jp-sQF"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision.models as models"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Saving and Loading Model Weights**"
      ],
      "metadata": {
        "id": "Z-QYWhucIr9o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.vgg16(weights='IMAGENET1K_V1')\n",
        "torch.save(model.state_dict(), 'model_weights.pth')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y73yUaUyIBdQ",
        "outputId": "91ca386f-6209-4248-b9e1-48678e42a521"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 528M/528M [00:07<00:00, 71.2MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.vgg16() # we do not specify ``weights``, i.e. create untrained model\n",
        "model.load_state_dict(torch.load('model_weights.pth', weights_only=True))\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "buDY0ZbqJoAQ",
        "outputId": "41d2e0d5-1c9c-4e8f-d6fe-01d19e8565d5"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VGG(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU(inplace=True)\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (6): ReLU(inplace=True)\n",
              "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (8): ReLU(inplace=True)\n",
              "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (13): ReLU(inplace=True)\n",
              "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (15): ReLU(inplace=True)\n",
              "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (18): ReLU(inplace=True)\n",
              "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (20): ReLU(inplace=True)\n",
              "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (22): ReLU(inplace=True)\n",
              "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (25): ReLU(inplace=True)\n",
              "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (27): ReLU(inplace=True)\n",
              "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (29): ReLU(inplace=True)\n",
              "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Dropout(p=0.5, inplace=False)\n",
              "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): Dropout(p=0.5, inplace=False)\n",
              "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Saving and Loading Models with Shape**"
      ],
      "metadata": {
        "id": "DCJEUn6EJvmQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model, 'model.pth')"
      ],
      "metadata": {
        "id": "XEi6-AbuJwfn"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.load('model.pth', weights_only=False)"
      ],
      "metadata": {
        "id": "ddhkplPNK46i"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QAdoQIKM-sQF"
      },
      "source": [
        "### Exercise\n",
        "### Q2\n",
        "a) Create a pytorch class for a neural network with 3 inputs, one hidden layer with 5 neurons and ReLU activatioin function, one output layer with 2 outputs. Use $torch.nn.init$ to initialize the biases to zeros and initialize the weights from a random distribution with vairiance $0.1$ and mean $0.0$.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "fY48EdgT-sQF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8200c9d6-3865-42f7-fed9-cc84c25c34b9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[-0.3566, -0.1552,  0.0519, -0.3366,  0.0977],\n",
              "        [-0.1617,  0.2685, -0.3114,  0.5047,  0.1659]], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ],
      "source": [
        "# code\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import math\n",
        "\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(3, 5),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(5, 2),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits\n",
        "\n",
        "torch.nn.init.zeros_(model.linear_relu_stack[0].bias)\n",
        "torch.nn.init.zeros_(model.linear_relu_stack[2].bias)\n",
        "torch.nn.init.normal_(model.linear_relu_stack[0].weight, mean=0.0, std=math.sqrt(0.1))\n",
        "torch.nn.init.normal_(model.linear_relu_stack[2].weight, mean=0.0, std=math.sqrt(0.1))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1SGbhANyN6Xx",
        "outputId": "9c927e12-cf3d-4345-cff4-b30ab62fdb86"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NeuralNetwork(\n",
              "  (linear_relu_stack): Sequential(\n",
              "    (0): Linear(in_features=3, out_features=5, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=5, out_features=2, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SyFcI26p-sQG"
      },
      "source": [
        "b) Instantiate the class to create a model. Access the weights and biases and print them.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "iYcfZDpa-sQG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab30fd5d-78f1-4b69-8619-593e15f05ac6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "linear_relu_stack.0.weight: tensor([[ 0.3774,  0.2328,  0.3459],\n",
            "        [ 0.0646, -0.2178,  0.0162],\n",
            "        [-0.5591,  0.0329, -0.4415],\n",
            "        [ 0.4316, -0.1069,  0.1645],\n",
            "        [ 0.2732,  0.2034, -0.4304]])\n",
            "linear_relu_stack.0.bias: tensor([ 0.0467,  0.5147,  0.0162, -0.4779,  0.4254])\n",
            "linear_relu_stack.2.weight: tensor([[ 0.3728, -0.0880,  0.3002,  0.1626,  0.2000],\n",
            "        [ 0.4351,  0.3026,  0.0636,  0.1249, -0.3836]])\n",
            "linear_relu_stack.2.bias: tensor([0.0372, 0.1845])\n"
          ]
        }
      ],
      "source": [
        "# code\n",
        "model = NeuralNetwork()\n",
        "\n",
        "for name, param in model.state_dict().items():\n",
        "    print(f\"{name}: {param}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UAXWpkhQ-sQG"
      },
      "source": [
        "c) Create a tensor X with 2 samples and 3 features randomly from a uniform distribution. Suppose the labels are 0 and 1, respectively for these two samples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "oj6G_m7i-sQG"
      },
      "outputs": [],
      "source": [
        "# code\n",
        "X = torch.rand(2, 3)\n",
        "y = torch.tensor([0, 1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3nZUBqot-sQG"
      },
      "source": [
        "d) Instantiate crossentropy loss."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "0woCiucK-sQG"
      },
      "outputs": [],
      "source": [
        "# code\n",
        "CELoss = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dp0h7ok_-sQG"
      },
      "source": [
        "e) Define an optimizer with stochastic gradient descent. Set the learning rate to 0.1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "8rl7CgoN-sQG"
      },
      "outputs": [],
      "source": [
        "# code\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "isxGS8qn-sQG"
      },
      "source": [
        "f) Set the gradients of the model to zero. Do backpropagation and find the jacobians of loss with respect to weights and biases in the first and second layers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "qol0_rAn-sQG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4000c8ad-120f-40b2-c657-ebb3c83b45d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradients of first layer weights:\n",
            "tensor([[ 0.0073,  0.0053,  0.0047],\n",
            "        [ 0.0455,  0.0335,  0.0293],\n",
            "        [ 0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000],\n",
            "        [-0.0680, -0.0501, -0.0438]])\n",
            "Gradients of first layer bias:\n",
            "tensor([ 0.0023,  0.0147,  0.0000,  0.0000, -0.0219]) \n",
            "\n",
            "\n",
            "Gradients of second layer weights:\n",
            "tensor([[-0.0917, -0.0094,  0.0000,  0.0000, -0.0329],\n",
            "        [ 0.0917,  0.0094,  0.0000,  0.0000,  0.0329]])\n",
            "Gradients of second layer bias:\n",
            "tensor([-0.0376,  0.0376])\n"
          ]
        }
      ],
      "source": [
        "# code\n",
        "optimizer.zero_grad()\n",
        "output = model(X)\n",
        "loss = CELoss(output, y)\n",
        "loss.backward()\n",
        "\n",
        "print(\"Gradients of first layer weights:\")\n",
        "print(model.linear_relu_stack[0].weight.grad)\n",
        "\n",
        "print(\"Gradients of first layer bias:\")\n",
        "print(model.linear_relu_stack[0].bias.grad,\"\\n\\n\")\n",
        "\n",
        "print(\"Gradients of second layer weights:\")\n",
        "print(model.linear_relu_stack[2].weight.grad)\n",
        "\n",
        "print(\"Gradients of second layer bias:\")\n",
        "print(model.linear_relu_stack[2].bias.grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y1xg6RCx-sQH"
      },
      "source": [
        "g) Update the parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "M0RR05Wv-sQH"
      },
      "outputs": [],
      "source": [
        "# code\n",
        "optimizer.step()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FnhZZKSK-sQH"
      },
      "source": [
        "h) Print the weight and biases in the first layer after update."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "id": "6BXIr-0I-sQH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c10b179-c33e-42d6-b107-87c12b0eb212"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "linear_relu_stack.0.weight: tensor([[ 0.3766,  0.2322,  0.3454],\n",
            "        [ 0.0601, -0.2212,  0.0133],\n",
            "        [-0.5591,  0.0329, -0.4415],\n",
            "        [ 0.4316, -0.1069,  0.1645],\n",
            "        [ 0.2800,  0.2084, -0.4260]])\n",
            "linear_relu_stack.0.bias: tensor([ 0.0465,  0.5132,  0.0162, -0.4779,  0.4276])\n",
            "linear_relu_stack.2.weight: tensor([[ 0.3819, -0.0871,  0.3002,  0.1626,  0.2033],\n",
            "        [ 0.4259,  0.3017,  0.0636,  0.1249, -0.3869]])\n",
            "linear_relu_stack.2.bias: tensor([0.0409, 0.1808])\n"
          ]
        }
      ],
      "source": [
        "# code\n",
        "for name, param in model.state_dict().items():\n",
        "    print(f\"{name}: {param}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ERRzeVe-sQH"
      },
      "source": [
        "i) save the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "id": "6N-OTQtH-sQH"
      },
      "outputs": [],
      "source": [
        "# code\n",
        "torch.save(model.state_dict(), 'model.pth')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N5eIOkHB-sQH"
      },
      "source": [
        "j) instantiate the network in Q2(a) agian to create ``model2``"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "id": "goTd72T_-sQH"
      },
      "outputs": [],
      "source": [
        "model2 = NeuralNetwork()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJwomiVZ-sQH"
      },
      "source": [
        "k) Print the weight and biases in the first layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "id": "uk4xW5S_-sQH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2ee8200-2949-4d7a-beee-bcbe0c161894"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "linear_relu_stack.0.weight: tensor([[-0.3500, -0.4872,  0.5173],\n",
            "        [ 0.4641,  0.2517,  0.4589],\n",
            "        [ 0.2395, -0.3973, -0.4249],\n",
            "        [-0.2584,  0.0776,  0.0504],\n",
            "        [ 0.1238, -0.0169,  0.0355]])\n",
            "linear_relu_stack.0.bias: tensor([ 0.2996,  0.4627, -0.0290, -0.3258,  0.5329])\n",
            "linear_relu_stack.2.weight: tensor([[ 0.2630,  0.0127,  0.3626, -0.2137,  0.4385],\n",
            "        [ 0.2120, -0.2872,  0.1858,  0.3297, -0.4443]])\n",
            "linear_relu_stack.2.bias: tensor([0.4379, 0.0590])\n"
          ]
        }
      ],
      "source": [
        "# code\n",
        "for name, param in model2.state_dict().items():\n",
        "    print(f\"{name}: {param}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-qtLepbv-sQH"
      },
      "source": [
        "l) Now, load the saved model and print the first layer weight and biases again."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "id": "tkkUKA2d-sQH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15c3903d-e6d3-4601-a5f3-95ff74500114"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "linear_relu_stack.0.weight: tensor([[ 0.3766,  0.2322,  0.3454],\n",
            "        [ 0.0601, -0.2212,  0.0133],\n",
            "        [-0.5591,  0.0329, -0.4415],\n",
            "        [ 0.4316, -0.1069,  0.1645],\n",
            "        [ 0.2800,  0.2084, -0.4260]])\n",
            "linear_relu_stack.0.bias: tensor([ 0.0465,  0.5132,  0.0162, -0.4779,  0.4276])\n",
            "linear_relu_stack.2.weight: tensor([[ 0.3819, -0.0871,  0.3002,  0.1626,  0.2033],\n",
            "        [ 0.4259,  0.3017,  0.0636,  0.1249, -0.3869]])\n",
            "linear_relu_stack.2.bias: tensor([0.0409, 0.1808])\n"
          ]
        }
      ],
      "source": [
        "# code\n",
        "model2.load_state_dict(torch.load('model.pth',weights_only=True))\n",
        "\n",
        "for name, param in model2.state_dict().items():\n",
        "    print(f\"{name}: {param}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}