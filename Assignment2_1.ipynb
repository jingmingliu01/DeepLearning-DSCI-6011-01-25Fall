{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jingmingliu01/DeepLearning-DSCI-6011-01-25Fall/blob/main/Assignment2_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wSats16-sP-"
      },
      "source": [
        "#### Instructions:  \n",
        "1. Libraries allowed: **Python basic libraries, numpy, pandas, scikit-learn (only for data processing), and pytorch.**\n",
        "2. Show all outputs.\n",
        "3. Submit jupyter notebook and a pdf export of the notebook.\n",
        "4. For practice examples, change variable name, shape, mathematical operations, nummerical values, tensor sizes etc. Be creative!\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1kW6okz-sQC"
      },
      "source": [
        "### Data Collection and Pre-processing\n",
        "#### Q1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ye1-LvJ2-sQC"
      },
      "source": [
        "#### a) Tensors\n",
        "Complete the tutorial at https://docs.pytorch.org/tutorials/beginner/basics/tensorqs_tutorial.html . make changes to the tensor, variable name etc. to make your example completely different from tutorial. Failing to do so will earn you zero credit.\n",
        "\n",
        "Add as many cells below as needed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "_pqB1y0o-sQD"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.1 Directly from data**"
      ],
      "metadata": {
        "id": "XnSt8kv-ByDR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = [[1,3.14],\n",
        "        [4,5],\n",
        "        [6,7]]"
      ],
      "metadata": {
        "id": "RmzqmRVd_gV0"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i2gMgdPYBFfd",
        "outputId": "64c9985b-c696-4f12-ab24-700f942102cf"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1, 3.14], [4, 5], [6, 7]]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_data = torch.tensor(data)"
      ],
      "metadata": {
        "id": "U0SfJEwEA1xP"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4RkhWAr9A3Jw",
        "outputId": "ffd17382-3d82-4fcd-c69f-bb84185a8d2b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.0000, 3.1400],\n",
              "        [4.0000, 5.0000],\n",
              "        [6.0000, 7.0000]])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xmuCQ1T3BIwD",
        "outputId": "036b20cc-1bf2-4680-d66b-e09237de1e0a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.2 From a NumPy array**"
      ],
      "metadata": {
        "id": "TLEXkpnQCm3z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np_data = np.array(data)"
      ],
      "metadata": {
        "id": "dApW1bWlCn7L"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8tB7mpf4DLKq",
        "outputId": "dc4eff8d-9df7-44b8-9633-b5fe3d71bc90"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.  , 3.14],\n",
              "       [4.  , 5.  ],\n",
              "       [6.  , 7.  ]])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_np_data=torch.from_numpy(np_data)"
      ],
      "metadata": {
        "id": "uHcT29W8C-sA"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_np_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t7rTX2HvDXXK",
        "outputId": "5369ce2a-816d-4dd0-ab3f-0544cc998ec0"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.0000, 3.1400],\n",
              "        [4.0000, 5.0000],\n",
              "        [6.0000, 7.0000]], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_np_data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bSbZqFqRDSOt",
        "outputId": "a4857d43-ca60-4f30-ba1c-8a995408d611"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.3 From another tensor**"
      ],
      "metadata": {
        "id": "zI207b_YDgZ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_ones = torch.ones_like(tensor_data)"
      ],
      "metadata": {
        "id": "fN74yVFYDiJN"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Ones Tensor: \\n {x_ones} \\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3skYYupEFDKz",
        "outputId": "9a3a84fa-fb76-4b52-fdc5-a9384a51c430"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ones Tensor: \n",
            " tensor([[1., 1.],\n",
            "        [1., 1.],\n",
            "        [1., 1.]]) \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_rand = torch.rand_like(tensor_data, dtype=torch.float)"
      ],
      "metadata": {
        "id": "MeQ--fr_FMv3"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Random Tensor: \\n {x_rand} \\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fl09jWRAFPMl",
        "outputId": "953d7b7b-ca45-4cab-d8c0-93697c6079e2"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Tensor: \n",
            " tensor([[0.9907, 0.5291],\n",
            "        [0.1090, 0.1152],\n",
            "        [0.4904, 0.4053]]) \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.4 With random or constant values**"
      ],
      "metadata": {
        "id": "uclTqIygFxNc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "shape=(4,2) # this is a tuple"
      ],
      "metadata": {
        "id": "iFEdoddEFypw"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rand = torch.rand(shape)\n",
        "ones = torch.ones(shape)\n",
        "zeros = torch.zeros(shape)"
      ],
      "metadata": {
        "id": "OgRtZfGCF-3e"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Random Tensor: \\n {rand} \\n\")\n",
        "print(f\"Ones Tensor: \\n {ones} \\n\")\n",
        "print(f\"Zeros Tensor: \\n {zeros}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ElwRbXxiGC9K",
        "outputId": "41991608-ddf7-4a03-897d-126e06ecd4a1"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Tensor: \n",
            " tensor([[0.0693, 0.2692],\n",
            "        [0.6609, 0.7814],\n",
            "        [0.5943, 0.3277],\n",
            "        [0.2587, 0.7313]]) \n",
            "\n",
            "Ones Tensor: \n",
            " tensor([[1., 1.],\n",
            "        [1., 1.],\n",
            "        [1., 1.],\n",
            "        [1., 1.]]) \n",
            "\n",
            "Zeros Tensor: \n",
            " tensor([[0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 0.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.5 Attributes of a Tensor**"
      ],
      "metadata": {
        "id": "hTNX_GZ2GfGd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = torch.rand(2,5)\n",
        "\n",
        "print(f\"Shape of tensor: {tensor.shape}\")\n",
        "print(f\"Datatype of tensor: {tensor.dtype}\")\n",
        "print(f\"Device tensor is stored on: {tensor.device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TcdqJoYNGdvf",
        "outputId": "c90e5aaf-e8b4-43dd-874b-90770f56e8ae"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of tensor: torch.Size([2, 5])\n",
            "Datatype of tensor: torch.float32\n",
            "Device tensor is stored on: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2 Operations on Tensors**"
      ],
      "metadata": {
        "id": "DtVFSbyrK3Bs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We move our tensor to the current accelerator if available\n",
        "if torch.accelerator.is_available():\n",
        "    tensor = tensor.to(torch.accelerator.current_accelerator())"
      ],
      "metadata": {
        "id": "LEvFtd0VNZlz"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.1 Standard numpy-like indexing and slicing:**"
      ],
      "metadata": {
        "id": "ofrv9rVzK4_M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = torch.ones(3, 3)\n",
        "print(f\"First row: {tensor[0]}\")\n",
        "print(f\"First column: {tensor[:, 0]}\")\n",
        "print(f\"Last column: {tensor[..., -1]}\")\n",
        "tensor[:,2] = 0\n",
        "print(tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rm-f6oVoK2qx",
        "outputId": "78a9c9d9-03ff-4f59-92d4-2c43b344d578"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First row: tensor([1., 1., 1.])\n",
            "First column: tensor([1., 1., 1.])\n",
            "Last column: tensor([1., 1., 1.])\n",
            "tensor([[1., 1., 0.],\n",
            "        [1., 1., 0.],\n",
            "        [1., 1., 0.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Joining tensors**"
      ],
      "metadata": {
        "id": "UpnsAoRTPEny"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t1 = torch.cat([tensor, tensor, tensor], dim=1)\n",
        "print(t1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6XEaBhL9PF5T",
        "outputId": "339e93b4-b5a3-4258-9104-2ee522e570f3"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 1., 0., 1., 1., 0., 1., 1., 0.],\n",
            "        [1., 1., 0., 1., 1., 0., 1., 1., 0.],\n",
            "        [1., 1., 0., 1., 1., 0., 1., 1., 0.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t2 = torch.cat([tensor, tensor, tensor], dim=0)\n",
        "print(t2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q6HlZ6IQQAqP",
        "outputId": "92faaaa1-fcba-4667-f075-56bb604d5e8a"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 1., 0.],\n",
            "        [1., 1., 0.],\n",
            "        [1., 1., 0.],\n",
            "        [1., 1., 0.],\n",
            "        [1., 1., 0.],\n",
            "        [1., 1., 0.],\n",
            "        [1., 1., 0.],\n",
            "        [1., 1., 0.],\n",
            "        [1., 1., 0.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Arithmetic operations**"
      ],
      "metadata": {
        "id": "zXPvka-YQIZV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This computes the matrix multiplication between two tensors. y1, y2, y3 will have the same value\n",
        "# ``tensor.T`` returns the transpose of a tensor\n",
        "y1 = tensor @ tensor.T\n",
        "y2 = tensor.matmul(tensor.T)\n",
        "\n",
        "y3 = torch.rand_like(y1)\n",
        "torch.matmul(tensor, tensor.T, out=y3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FwgIJDNDQJVv",
        "outputId": "f1d3ba95-cf01-49a3-8764-2e1e99844825"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2., 2., 2.],\n",
              "        [2., 2., 2.],\n",
              "        [2., 2., 2.]])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79HrjVkAUgrg",
        "outputId": "6aec31ed-bbd9-44c4-e503-7319ac44344d"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2., 2., 2.],\n",
              "        [2., 2., 2.],\n",
              "        [2., 2., 2.]])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9BuLiXL6Uh1w",
        "outputId": "b56bcda9-8bbd-4323-93fa-c970c86c2228"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2., 2., 2.],\n",
              "        [2., 2., 2.],\n",
              "        [2., 2., 2.]])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x_dGwAYUUibB",
        "outputId": "68a22ae2-39ec-4f09-f08b-8f5434d06ea1"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2., 2., 2.],\n",
              "        [2., 2., 2.],\n",
              "        [2., 2., 2.]])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This computes the element-wise product. z1, z2, z3 will have the same value\n",
        "z1 = tensor * tensor\n",
        "z2 = tensor.mul(tensor)\n",
        "\n",
        "z3 = torch.rand_like(tensor)\n",
        "torch.mul(tensor, tensor, out=z3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ll0XkqNU2To",
        "outputId": "0cc94bba-9612-4036-9806-e0949dd5e144"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 0.],\n",
              "        [1., 1., 0.],\n",
              "        [1., 1., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Single-element tensors**"
      ],
      "metadata": {
        "id": "XdMshTNPVzV9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "agg = tensor.sum()\n",
        "agg_item = agg.item()\n",
        "print(agg_item, type(agg_item))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iNGzf5sSVzpv",
        "outputId": "24f52bb7-537d-40e5-ed70-8a51566374d0"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6.0 <class 'float'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**In-place operations**"
      ],
      "metadata": {
        "id": "RArixVOmV5ng"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = torch.ones(3,3)\n",
        "print(f\"{tensor} \\n\")\n",
        "tensor.add_(3)\n",
        "print(tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8bH3zXtxV9hh",
        "outputId": "1410b5cb-1c08-4a74-f426-74f570e8a0cf"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.]]) \n",
            "\n",
            "tensor([[4., 4., 4.],\n",
            "        [4., 4., 4.],\n",
            "        [4., 4., 4.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3 Bridge with NumPy**"
      ],
      "metadata": {
        "id": "gsh3xp6eWm0h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.1 Tensor to NumPy array**"
      ],
      "metadata": {
        "id": "X2BcepljdvhA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t = torch.ones(3)\n",
        "print(f\"t: {t}\")\n",
        "n = t.numpy()\n",
        "print(f\"n: {n}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aH96QFuHWoMV",
        "outputId": "cc388ea2-3ebe-4691-bb5f-fa71cd1fc5f2"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "t: tensor([1., 1., 1.])\n",
            "n: [1. 1. 1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t.add_(1)\n",
        "print(f\"t: {t}\")\n",
        "print(f\"n: {n}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iE3g0h43LSpt",
        "outputId": "2e25ba32-f51f-4388-867f-084656e7fe00"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "t: tensor([2., 2., 2.])\n",
            "n: [2. 2. 2.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n = np.ones(5)\n",
        "t = torch.from_numpy(n)"
      ],
      "metadata": {
        "id": "UmQweGy8LUGq"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.add(n, 1, out=n)\n",
        "print(f\"t: {t}\")\n",
        "print(f\"n: {n}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "owl-A23kLdW2",
        "outputId": "9e9d7688-9a8e-47c3-8a6a-8a1a0080fe01"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "t: tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n",
            "n: [2. 2. 2. 2. 2.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NzvrRVvd-sQD"
      },
      "source": [
        "#### b) Autormatic differentiation\n",
        "Complete the tutorial at https://pytorch.org/tutorials/beginner/basics/autogradqs_tutorial.html . Again, make changes to the tensor, variable name etc. to make your example completely different from tutorial. Failing to do so will earn you zero credit.\n",
        "\n",
        "Add as many cells below as needed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "Fl-YYzVw-sQD"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "x = torch.ones(6)  # input tensor\n",
        "y = torch.zeros(2)  # expected output\n",
        "w = torch.randn(6, 2, requires_grad=True)\n",
        "b = torch.randn(2, requires_grad=True)\n",
        "z = x @ w +b\n",
        "loss = torch.nn.functional.binary_cross_entropy_with_logits(z, y)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Gradient function for z = {z.grad_fn}\")\n",
        "print(f\"Gradient function for loss = {loss.grad_fn}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eDaLJtPyQkXS",
        "outputId": "eb0596dd-a6d9-47fa-e56b-b395ca7889ff"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradient function for z = <AddBackward0 object at 0x7a7dcdcbbd30>\n",
            "Gradient function for loss = <BinaryCrossEntropyWithLogitsBackward0 object at 0x7a7dcdcba410>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss.backward()\n",
        "print(w.grad)\n",
        "print(b.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0HVW9Y8GQ8kw",
        "outputId": "ce1a846e-426d-4232-aaca-014447f7a911"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.3964, 0.2577],\n",
            "        [0.3964, 0.2577],\n",
            "        [0.3964, 0.2577],\n",
            "        [0.3964, 0.2577],\n",
            "        [0.3964, 0.2577],\n",
            "        [0.3964, 0.2577]])\n",
            "tensor([0.3964, 0.2577])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Disabling Gradient Tracking**"
      ],
      "metadata": {
        "id": "cWW7N7BoRiWC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "z = torch.matmul(x, w)+b\n",
        "print(z.requires_grad)\n",
        "\n",
        "with torch.no_grad():\n",
        "    z = torch.matmul(x, w)+b\n",
        "print(z.requires_grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RJ19zxvrRhqB",
        "outputId": "11debf00-03e4-45c5-d6e7-ef5ebbd046f7"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z = torch.matmul(x, w)+b\n",
        "z_det = z.detach()\n",
        "print(z_det.requires_grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "anJHWL3IRwgB",
        "outputId": "e3368832-4480-4804-fd57-b29ee77a6e8c"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Jacobian Product**"
      ],
      "metadata": {
        "id": "lZyrAb_TwjLo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inp = torch.eye(4, 5, requires_grad=True)"
      ],
      "metadata": {
        "id": "mGeVGog1p3qm"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_mwkE1nwteO",
        "outputId": "3cbdd686-7c84-4302-e3e8-08815684859e"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 0., 0., 0., 0.],\n",
              "        [0., 1., 0., 0., 0.],\n",
              "        [0., 0., 1., 0., 0.],\n",
              "        [0., 0., 0., 1., 0.]], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out = (inp+1).pow(2).t()"
      ],
      "metadata": {
        "id": "AtioQ5qDwhQv"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fn8La8Guwwm-",
        "outputId": "99816224-175e-491a-edf3-e6dcd72eec0e"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[4., 1., 1., 1.],\n",
              "        [1., 4., 1., 1.],\n",
              "        [1., 1., 4., 1.],\n",
              "        [1., 1., 1., 4.],\n",
              "        [1., 1., 1., 1.]], grad_fn=<TBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out.backward(torch.ones_like(out), retain_graph=True)\n",
        "print(f\"First call\\n{inp.grad}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZGZQOoKewiaq",
        "outputId": "48ea29e4-5ec9-41d1-ed85-6b3e0784ee7e"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First call\n",
            "tensor([[4., 2., 2., 2., 2.],\n",
            "        [2., 4., 2., 2., 2.],\n",
            "        [2., 2., 4., 2., 2.],\n",
            "        [2., 2., 2., 4., 2.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out.backward(torch.ones_like(out), retain_graph=True)\n",
        "print(f\"\\nSecond call\\n{inp.grad}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9s3pnNGXwp88",
        "outputId": "9a8f4b60-e788-40b2-b2b4-19521a82bfbb"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Second call\n",
            "tensor([[8., 4., 4., 4., 4.],\n",
            "        [4., 8., 4., 4., 4.],\n",
            "        [4., 4., 8., 4., 4.],\n",
            "        [4., 4., 4., 8., 4.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inp.grad.zero_()\n",
        "out.backward(torch.ones_like(out), retain_graph=True)\n",
        "print(f\"\\nCall after zeroing gradients\\n{inp.grad}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Bu7QoUNwq9R",
        "outputId": "6c8f0cab-11ab-431e-e097-01b50719d99e"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Call after zeroing gradients\n",
            "tensor([[4., 2., 2., 2., 2.],\n",
            "        [2., 4., 2., 2., 2.],\n",
            "        [2., 2., 4., 2., 2.],\n",
            "        [2., 2., 2., 4., 2.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQPC5P8n-sQD"
      },
      "source": [
        "#### c) Datasets and Dataloader\n",
        "\n",
        "Download the \"Hand Keypoint detection\" dataset from https://www.kaggle.com/datasets/pablocumbrera/hand-keypoint-detection .\n",
        "1. Define a pytorch Dataset class, HandKpDetection.\n",
        "   1. Implement ``__init__`` method, in which gather the filepaths to all images in the dataset and store them in a list. Don't load the entire dataset or images in this method. Both image and label file share the same prefix, so just storing filepath for images will work.\n",
        "   2. implement ``__len__`` method.\n",
        "   3. Implement ``__getitem__(self, index)`` where you will load just one sample corresponding to the ``index`` in the method argument. Use the filepath information in the init methods to load both image and keypoints. Reshape the image to $32\\times 32$ and keypoints to $20\\times 2$\n",
        "2. Implement Dataloaders with a minibatch size of 2. Convert both image and keypoints to ``torch.tensor``.\n",
        "3. Visualize the images and print the keypoints in the first minibatch\n",
        "\n",
        "Add as many cells below as needed."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Download the dataset**"
      ],
      "metadata": {
        "id": "ooAUrNUQJyR6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GJB4D5cW-sQE",
        "outputId": "61d23861-448b-4d5c-b20f-aa992031cf49"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/pablocumbrera/hand-keypoint-detection?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 632M/632M [00:05<00:00, 129MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/pablocumbrera/hand-keypoint-detection/versions/1\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"pablocumbrera/hand-keypoint-detection\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define a pytorch Dataset class, HandKpDetection**"
      ],
      "metadata": {
        "id": "L_miBbiBJ2JU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, glob, json\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "e_CApMiB9WsP"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class HandKpDetection(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            root_dir (str): Dataset root, e.g.\n",
        "                '/root/.cache/kagglehub/datasets/pablocumbrera/hand-keypoint-detection/versions/1/hand_labels_synth'\n",
        "            transform: optional torchvision transform for images\n",
        "        \"\"\"\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "\n",
        "        # collect all .jpg files under synth1..synth4\n",
        "        self.image_paths = []\n",
        "        for folder in [\"synth1\", \"synth2\", \"synth3\", \"synth4\"]:\n",
        "            self.image_paths.extend(sorted(glob.glob(os.path.join(root_dir, folder, \"*.jpg\"))))\n",
        "\n",
        "        print(\"Found\", len(self.image_paths), \"images\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "      # --- load image ---\n",
        "      img_path = self.image_paths[index]\n",
        "      image = Image.open(img_path).convert(\"RGB\")\n",
        "      orig_w, orig_h = image.size   # original size\n",
        "\n",
        "      # resize\n",
        "      image = image.resize((32, 32))\n",
        "      new_w, new_h = 32, 32\n",
        "\n",
        "      # convert to tensor\n",
        "      image = np.array(image, dtype=np.float32) / 255.0\n",
        "      image = np.transpose(image, (2, 0, 1))\n",
        "      image = torch.tensor(image)\n",
        "\n",
        "      # --- load keypoints ---\n",
        "      json_path = img_path.replace(\".jpg\", \".json\")\n",
        "      with open(json_path, \"r\") as f:\n",
        "          ann = json.load(f)\n",
        "      keypoints = np.array(ann[\"hand_pts\"], dtype=np.float32)[:, :2]\n",
        "      keypoints = keypoints.reshape(-1, 2)[:20]\n",
        "\n",
        "      # scale keypoints to new size\n",
        "      scale_x = new_w / orig_w\n",
        "      scale_y = new_h / orig_h\n",
        "      keypoints[:, 0] *= scale_x\n",
        "      keypoints[:, 1] *= scale_y\n",
        "\n",
        "      keypoints = torch.tensor(keypoints)\n",
        "\n",
        "      return image, keypoints\n"
      ],
      "metadata": {
        "id": "wRk8ojUx6veB"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Implement Dataloaders with a minibatch size of 2. Convert both image and keypoints to torch.tensor.**"
      ],
      "metadata": {
        "id": "Z44QQElOJ4uL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "root = \"/root/.cache/kagglehub/datasets/pablocumbrera/hand-keypoint-detection/versions/1/hand_labels_synth\"\n",
        "dataset = HandKpDetection(root)\n",
        "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)\n",
        "\n",
        "images, keypoints = next(iter(dataloader))\n",
        "print(\"Batch images:\", images.shape)      # [2, 3, 32, 32]  [batch_size, channels, shape_x, shape_y]\n",
        "print(\"Batch keypoints:\", keypoints.shape) # [2, 20, 2]     [batch_size, shape_x, shape_y]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SxMNMNKV91D_",
        "outputId": "99e4fe38-cb26-4748-f1d3-4b55f5c82893"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 14261 images\n",
            "Batch images: torch.Size([2, 3, 32, 32])\n",
            "Batch keypoints: torch.Size([2, 20, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Visualize the images and print the keypoints in the first minibatch**"
      ],
      "metadata": {
        "id": "vlSwTGW7KMvc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# get the first minibatch\n",
        "images, keypoints = next(iter(dataloader))\n",
        "\n",
        "print(\"First minibatch keypoints (tensor):\")\n",
        "print(keypoints)\n",
        "\n",
        "# visualize both images in the minibatch\n",
        "fig, axes = plt.subplots(1, 2, figsize=(6, 3))\n",
        "\n",
        "for i in range(2):  # because batch_size = 2\n",
        "    img = images[i].permute(1, 2, 0).numpy()   # CHW -> HWC\n",
        "    kp = keypoints[i].numpy()\n",
        "\n",
        "    axes[i].imshow(img)\n",
        "    axes[i].scatter(kp[:, 0], kp[:, 1], c='red', s=10)  # plot keypoints\n",
        "    axes[i].set_title(f\"Sample {i}\")\n",
        "    axes[i].axis(\"off\")\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "TRN-h3LMJuNw",
        "outputId": "a1328985-70df-4be4-fc29-57e57259b6ab"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First minibatch keypoints (tensor):\n",
            "tensor([[[18.8417, 16.0015],\n",
            "         [18.0125, 16.5376],\n",
            "         [17.1612, 16.7042],\n",
            "         [16.1864, 16.8205],\n",
            "         [ 0.0000,  0.0000],\n",
            "         [16.2965, 16.1416],\n",
            "         [15.4284, 16.1616],\n",
            "         [14.6583, 16.3780],\n",
            "         [ 0.0000,  0.0000],\n",
            "         [16.2193, 15.8830],\n",
            "         [15.2294, 15.7947],\n",
            "         [14.5839, 15.9803],\n",
            "         [ 0.0000,  0.0000],\n",
            "         [16.3774, 15.7657],\n",
            "         [15.5360, 15.6582],\n",
            "         [14.9376, 15.8091],\n",
            "         [ 0.0000,  0.0000],\n",
            "         [16.6569, 15.7312],\n",
            "         [15.7037, 15.6752],\n",
            "         [15.3216, 15.7910]],\n",
            "\n",
            "        [[19.1302, 17.6419],\n",
            "         [18.5524, 16.1821],\n",
            "         [17.2766, 14.8454],\n",
            "         [15.9123, 14.1921],\n",
            "         [ 0.0000,  0.0000],\n",
            "         [16.9338, 15.5863],\n",
            "         [15.4189, 14.9634],\n",
            "         [15.0314, 14.8810],\n",
            "         [ 0.0000,  0.0000],\n",
            "         [16.5269, 16.3090],\n",
            "         [15.0948, 15.5956],\n",
            "         [14.8860, 15.5257],\n",
            "         [ 0.0000,  0.0000],\n",
            "         [16.2764, 16.9248],\n",
            "         [15.1387, 16.3919],\n",
            "         [15.0429, 16.3472],\n",
            "         [ 0.0000,  0.0000],\n",
            "         [16.0652, 17.5749],\n",
            "         [14.8719, 17.0874],\n",
            "         [15.0840, 17.0620]]])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x300 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mroxfk8H-sQE"
      },
      "source": [
        "#### d) Build model\n",
        "Complete the tutorial at https://pytorch.org/tutorials/beginner/basics/buildmodel_tutorial.html.\n",
        "\n",
        "Add as many cells below as needed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "t65S1yL--sQE"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4LTeAco7-sQE"
      },
      "source": [
        "#### e) Optimization loop\n",
        "Complete the tutorial at https://pytorch.org/tutorials/beginner/basics/optimization_tutorial.html.\n",
        "\n",
        "Add as many cells below as needed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "EbSkuBqN-sQF"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QWKoy50_-sQF"
      },
      "source": [
        "#### f) Save, load, and use model\n",
        "Complete the tutorial at https://pytorch.org/tutorials/beginner/basics/saveloadrun_tutorial.html.\n",
        "\n",
        "Add as many cells below as needed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "ldWeI4Jp-sQF"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QAdoQIKM-sQF"
      },
      "source": [
        "### Exercise\n",
        "### Q2\n",
        "a) Create a pytorch class for a neural network with 3 inputs, one hidden layer with 5 neurons and ReLU activatioin function, one output layer with 2 outputs. Use $torch.nn.init$ to initialize the biases to zeros and initialize the weights from a random distribution with vairiance $0.1$ and mean $0.0$.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "fY48EdgT-sQF"
      },
      "outputs": [],
      "source": [
        "# code\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SyFcI26p-sQG"
      },
      "source": [
        "b) Instantiate the class to create a model. Access the weights and biases and print them.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "iYcfZDpa-sQG"
      },
      "outputs": [],
      "source": [
        "# code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UAXWpkhQ-sQG"
      },
      "source": [
        "c) Create a tensor X with 2 samples and 3 features randomly from a uniform distribution. Suppose the labels are 0 and 1, respectively for these two samples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "oj6G_m7i-sQG"
      },
      "outputs": [],
      "source": [
        "# code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3nZUBqot-sQG"
      },
      "source": [
        "d) Instantiate crossentropy loss."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "0woCiucK-sQG"
      },
      "outputs": [],
      "source": [
        "# code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dp0h7ok_-sQG"
      },
      "source": [
        "e) Define an optimizer with stochastic gradient descent. Set the learning rate to 0.1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "8rl7CgoN-sQG"
      },
      "outputs": [],
      "source": [
        "# code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "isxGS8qn-sQG"
      },
      "source": [
        "f) Set the gradients of the model to zero. Do backpropagation and find the jacobians of loss with respect to weights and biases in the first and second layers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "qol0_rAn-sQG"
      },
      "outputs": [],
      "source": [
        "# code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y1xg6RCx-sQH"
      },
      "source": [
        "g) Update the parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "M0RR05Wv-sQH"
      },
      "outputs": [],
      "source": [
        "# code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FnhZZKSK-sQH"
      },
      "source": [
        "h) Print the weight and biases in the first layer after update."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "6BXIr-0I-sQH"
      },
      "outputs": [],
      "source": [
        "# code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ERRzeVe-sQH"
      },
      "source": [
        "i) save the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "6N-OTQtH-sQH"
      },
      "outputs": [],
      "source": [
        "# code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N5eIOkHB-sQH"
      },
      "source": [
        "j) instantiate the network in Q2(a) agian to create ``model2``"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "goTd72T_-sQH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJwomiVZ-sQH"
      },
      "source": [
        "k) Print the weight and biases in the first layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "uk4xW5S_-sQH"
      },
      "outputs": [],
      "source": [
        "# code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-qtLepbv-sQH"
      },
      "source": [
        "l) Now, load the saved model and print the first layer weight and biases again."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "tkkUKA2d-sQH"
      },
      "outputs": [],
      "source": [
        "# code"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}