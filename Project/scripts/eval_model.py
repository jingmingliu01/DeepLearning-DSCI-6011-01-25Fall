#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
YOLACT++ Model Evaluation Script
åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°æ¨¡å‹æ€§èƒ½
"""

import sys
import os
import argparse
import subprocess
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
PROJECT_ROOT = Path(__file__).parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

import config

def find_best_model():
    """æŸ¥æ‰¾æœ€ä½³æ¨¡å‹æƒé‡"""
    if config.BEST_WEIGHTS.exists():
        return config.BEST_WEIGHTS

    # æŸ¥æ‰¾æœ€æ–°çš„checkpoint
    checkpoints = list(config.CHECKPOINTS_DIR.glob("*.pth"))
    if not checkpoints:
        print(f"âŒ Error: No model weights found in {config.CHECKPOINTS_DIR}")
        return None

    # æŒ‰ä¿®æ”¹æ—¶é—´æ’åº
    latest_checkpoint = max(checkpoints, key=lambda p: p.stat().st_mtime)
    print(f"â„¹ï¸  Using latest checkpoint: {latest_checkpoint}")
    return latest_checkpoint

def run_evaluation(model_path, output_dir=None):
    """è¿è¡Œè¯„ä¼°"""
    if output_dir is None:
        output_dir = config.RESULTS_DIR

    output_dir.mkdir(parents=True, exist_ok=True)

    print("\nğŸ“Š Starting model evaluation...")
    print(f"\nè¯„ä¼°é…ç½®:")
    print(f"  - Model: {model_path}")
    print(f"  - Test Data: {config.PROCESSED_DATA_DIR / 'test'}")
    print(f"  - Output: {output_dir}")

    cmd = [
        'python', str(config.YOLACT_ROOT / 'eval.py'),
        f'--trained_model={model_path}',
        f'--score_threshold={config.INFERENCE_SCORE_THRESHOLD}',
        f'--top_k={config.TOP_K}',
        f'--config=campus_objects_config',
        f'--output_coco_json',
        '--dataset=campus_objects_dataset:test',
    ]

    if config.USE_GPU:
        cmd.append('--cuda=True')

    print(f"\næ‰§è¡Œå‘½ä»¤:")
    print(f"  {' '.join(cmd)}")
    print("\n" + "="*60)

    try:
        os.chdir(config.YOLACT_ROOT)
        subprocess.run(cmd, check=True)

        print("\n" + "="*60)
        print("âœ… Evaluation completed successfully!")
        print(f"\nç»“æœä¿å­˜åœ¨: {output_dir}")

        return True

    except subprocess.CalledProcessError as e:
        print(f"\nâŒ Evaluation failed: {e}")
        return False
    except KeyboardInterrupt:
        print("\n\nâš ï¸  Evaluation interrupted by user")
        return False
    finally:
        os.chdir(PROJECT_ROOT)

def main():
    parser = argparse.ArgumentParser(description='Evaluate YOLACT++ model')
    parser.add_argument('--model', type=str,
                        help='Path to model weights (default: auto-detect)')
    parser.add_argument('--output', type=str,
                        help='Output directory for results')
    args = parser.parse_args()

    print("\n" + "="*60)
    print(" YOLACT++ Model Evaluation")
    print("="*60)

    # æŸ¥æ‰¾æ¨¡å‹
    model_path = args.model if args.model else find_best_model()
    if model_path is None:
        sys.exit(1)

    model_path = Path(model_path)
    if not model_path.exists():
        print(f"âŒ Error: Model not found: {model_path}")
        sys.exit(1)

    # è¿è¡Œè¯„ä¼°
    output_dir = Path(args.output) if args.output else None
    success = run_evaluation(model_path, output_dir)

    sys.exit(0 if success else 1)

if __name__ == "__main__":
    main()
