#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
YOLACT++ Campus Objects - Configuration File
é›†ä¸­ç®¡ç†æ‰€æœ‰é…ç½®å‚æ•°
"""

import os
from pathlib import Path

# ==================== é¡¹ç›®è·¯å¾„é…ç½® ====================

# é¡¹ç›®æ ¹ç›®å½•
PROJECT_ROOT = Path(__file__).parent.absolute()

# æ•°æ®ç›®å½•
DATA_ROOT = PROJECT_ROOT / "data"
RAW_IMAGES_DIR = DATA_ROOT / "raw_images"
COCO_ANNOTATIONS_DIR = DATA_ROOT / "coco_annotations"
PROCESSED_DATA_DIR = DATA_ROOT / "processed"

# YOLACTä»£ç ç›®å½•
YOLACT_ROOT = PROJECT_ROOT / "yolact"

# æƒé‡ç›®å½•
WEIGHTS_DIR = PROJECT_ROOT / "weights"
PRETRAINED_WEIGHTS = WEIGHTS_DIR / "yolact_plus_resnet50_54_800000.pth"
BEST_WEIGHTS = WEIGHTS_DIR / "campus_objects_best.pth"

# è¾“å‡ºç›®å½•
OUTPUTS_DIR = PROJECT_ROOT / "outputs"
LOGS_DIR = OUTPUTS_DIR / "logs"
CHECKPOINTS_DIR = OUTPUTS_DIR / "checkpoints"
RESULTS_DIR = OUTPUTS_DIR / "results"

# Webåº”ç”¨ç›®å½•
WEB_APP_DIR = PROJECT_ROOT / "web_app"

# ==================== æ•°æ®é›†é…ç½® ====================

# ç±»åˆ«å®šä¹‰ï¼ˆæŒ‰ç…§ä½ çš„é¡¹ç›®ï¼‰
CLASSES = [
    'Whiteboard',              # ç™½æ¿
    'DrinkingWaterFountain',   # é¥®æ°´æœº
    'UniversityLogo'           # å¤§å­¦æ ‡å¿—
]

NUM_CLASSES = len(CLASSES)

# COCOæ ‡æ³¨æ–‡ä»¶è·¯å¾„
COCO_ANNOTATION_FILE = COCO_ANNOTATIONS_DIR / "instances.json"

# æ•°æ®é›†åˆ’åˆ†æ¯”ä¾‹
TRAIN_RATIO = 0.7    # 70% è®­ç»ƒé›†
VAL_RATIO = 0.2      # 20% éªŒè¯é›†
TEST_RATIO = 0.1     # 10% æµ‹è¯•é›†

# éšæœºç§å­ï¼ˆä¿è¯å¯å¤ç°æ€§ï¼‰
RANDOM_SEED = 42

# å›¾åƒå°ºå¯¸ï¼ˆYOLACT++æ ‡å‡†è¾“å…¥ï¼‰
IMAGE_SIZE = 550

# æ•°æ®å¢å¼ºå‚æ•°
DATA_AUGMENTATION = {
    'horizontal_flip': True,
    'brightness': 0.2,
    'contrast': 0.2,
    'saturation': 0.2,
    'hue': 0.05
}

# ==================== æ¨¡å‹é…ç½® ====================

# éª¨å¹²ç½‘ç»œ
BACKBONE = 'resnet50'  # å¯é€‰: resnet50, resnet101

# æ˜¯å¦ä½¿ç”¨YOLACT++ç‰¹æ€§
USE_YOLACT_PLUS = True

# å±‚å†»ç»“é…ç½®ï¼ˆè¿ç§»å­¦ä¹ å…³é”®ï¼‰
FREEZE_LAYERS = {
    'backbone': True,        # å†»ç»“ResNetéª¨å¹²ç½‘ç»œ
    'fpn': True,            # å†»ç»“ç‰¹å¾é‡‘å­—å¡”ç½‘ç»œ
    'proto_net': True,      # å†»ç»“åŸå‹ç”Ÿæˆç½‘ç»œ
    'prediction_layers': {  # é¢„æµ‹å±‚éƒ¨åˆ†å†»ç»“
        'bbox': True,       # å†»ç»“è¾¹ç•Œæ¡†é¢„æµ‹
        'mask': True,       # å†»ç»“æ©ç ç³»æ•°é¢„æµ‹
        'class': False      # ä¸å†»ç»“åˆ†ç±»å±‚ï¼ˆéœ€è¦è®­ç»ƒï¼‰
    }
}

# ==================== è®­ç»ƒé…ç½® ====================

# è®­ç»ƒè¶…å‚æ•°
BATCH_SIZE = 8           # æ ¹æ®GPUå†…å­˜è°ƒæ•´ï¼ˆ8GBæ˜¾å­˜å»ºè®®4-8ï¼‰
NUM_EPOCHS = 50          # è¿ç§»å­¦ä¹ é€šå¸¸30-50ä¸ªepochè¶³å¤Ÿ
LEARNING_RATE = 1e-3     # ç”±äºåªè®­ç»ƒåˆ†ç±»å±‚ï¼Œå¯ä»¥ç”¨è¾ƒé«˜å­¦ä¹ ç‡
WEIGHT_DECAY = 5e-4
MOMENTUM = 0.9

# å­¦ä¹ ç‡è°ƒåº¦
LR_SCHEDULER = {
    'type': 'step',       # å¯é€‰: step, cosine, plateau
    'step_size': 10,      # æ¯10ä¸ªepochè¡°å‡
    'gamma': 0.1          # è¡°å‡å› å­
}

# ä¼˜åŒ–å™¨
OPTIMIZER = 'SGD'  # å¯é€‰: SGD, Adam

# GPUè®¾ç½®
USE_GPU = True
GPU_ID = 0  # å¦‚æœæœ‰å¤šä¸ªGPUï¼ŒæŒ‡å®šä½¿ç”¨å“ªä¸ª
NUM_WORKERS = 4  # æ•°æ®åŠ è½½çº¿ç¨‹æ•°

# è®­ç»ƒæ—¥å¿—
LOG_INTERVAL = 10        # æ¯10ä¸ªbatchæ‰“å°ä¸€æ¬¡
SAVE_INTERVAL = 5        # æ¯5ä¸ªepochä¿å­˜ä¸€æ¬¡
EVAL_INTERVAL = 2        # æ¯2ä¸ªepochéªŒè¯ä¸€æ¬¡

# æ—©åœç­–ç•¥
EARLY_STOPPING = {
    'enabled': True,
    'patience': 10,       # è¿ç»­10ä¸ªepochæ²¡æå‡åˆ™åœæ­¢
    'min_delta': 0.001    # æœ€å°æå‡é˜ˆå€¼
}

# ==================== è¯„ä¼°é…ç½® ====================

# è¯„ä¼°æŒ‡æ ‡
EVAL_METRICS = ['bbox', 'segm']  # è¾¹ç•Œæ¡†å’Œåˆ†å‰²æ©ç 

# mAPè®¡ç®—
MAP_IOU_THRESHOLDS = [0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95]

# NMSï¼ˆéæå¤§å€¼æŠ‘åˆ¶ï¼‰é˜ˆå€¼
NMS_THRESHOLD = 0.5

# ç½®ä¿¡åº¦é˜ˆå€¼
SCORE_THRESHOLD = 0.3

# æœ€å¤§æ£€æµ‹æ•°é‡
MAX_DETECTIONS = 100

# ==================== æ¨ç†é…ç½® ====================

# æ¨ç†æ—¶çš„ç½®ä¿¡åº¦é˜ˆå€¼
INFERENCE_SCORE_THRESHOLD = 0.5

# æ¨ç†æ—¶çš„NMSé˜ˆå€¼
INFERENCE_NMS_THRESHOLD = 0.5

# Top-Kæ£€æµ‹
TOP_K = 15

# å¯è§†åŒ–é…ç½®
VISUALIZATION = {
    'show_bbox': True,        # æ˜¾ç¤ºè¾¹ç•Œæ¡†
    'show_mask': True,        # æ˜¾ç¤ºåˆ†å‰²æ©ç 
    'show_score': True,       # æ˜¾ç¤ºç½®ä¿¡åº¦
    'mask_alpha': 0.45,       # æ©ç é€æ˜åº¦
    'bbox_thickness': 2,      # è¾¹ç•Œæ¡†çº¿å®½
    'font_scale': 0.5         # å­—ä½“å¤§å°
}

# é¢œè‰²æ˜ å°„ï¼ˆRGBï¼‰
CLASS_COLORS = {
    'Whiteboard': (255, 255, 255),           # ç™½è‰²
    'DrinkingWaterFountain': (0, 191, 255),  # å¤©è“è‰²
    'UniversityLogo': (255, 215, 0)          # é‡‘è‰²
}

# ==================== Webåº”ç”¨é…ç½® ====================

# Flaské…ç½®
FLASK_HOST = '0.0.0.0'
FLASK_PORT = 5000
FLASK_DEBUG = False

# ä¸Šä¼ æ–‡ä»¶é…ç½®
UPLOAD_FOLDER = WEB_APP_DIR / "static" / "uploads"
ALLOWED_EXTENSIONS = {'png', 'jpg', 'jpeg', 'gif', 'bmp'}
MAX_CONTENT_LENGTH = 16 * 1024 * 1024  # 16MB

# ==================== è¾…åŠ©å‡½æ•° ====================

def create_dirs():
    """åˆ›å»ºå¿…è¦çš„ç›®å½•"""
    dirs = [
        DATA_ROOT,
        RAW_IMAGES_DIR,
        COCO_ANNOTATIONS_DIR,
        PROCESSED_DATA_DIR,
        PROCESSED_DATA_DIR / "train",
        PROCESSED_DATA_DIR / "val",
        PROCESSED_DATA_DIR / "test",
        WEIGHTS_DIR,
        OUTPUTS_DIR,
        LOGS_DIR,
        CHECKPOINTS_DIR,
        RESULTS_DIR,
        RESULTS_DIR / "images",
        WEB_APP_DIR / "static" / "uploads"
    ]

    for dir_path in dirs:
        dir_path.mkdir(parents=True, exist_ok=True)

    print("âœ“ All directories created successfully!")

def print_config():
    """æ‰“å°é…ç½®ä¿¡æ¯"""
    print("\n" + "="*60)
    print(" YOLACT++ Campus Objects - Configuration")
    print("="*60)
    print(f"\nğŸ“ Project Root: {PROJECT_ROOT}")
    print(f"\nğŸ¯ Classes ({NUM_CLASSES}):")
    for i, cls in enumerate(CLASSES, 1):
        print(f"   {i}. {cls}")
    print(f"\nğŸ–¼ï¸  Image Size: {IMAGE_SIZE}x{IMAGE_SIZE}")
    print(f"ğŸ“Š Dataset Split: Train {TRAIN_RATIO*100:.0f}% | Val {VAL_RATIO*100:.0f}% | Test {TEST_RATIO*100:.0f}%")
    print(f"\nğŸ”§ Training Config:")
    print(f"   - Batch Size: {BATCH_SIZE}")
    print(f"   - Epochs: {NUM_EPOCHS}")
    print(f"   - Learning Rate: {LEARNING_RATE}")
    print(f"   - Backbone: {BACKBONE}")
    print(f"\nğŸ§Š Frozen Layers:")
    print(f"   - Backbone: {'âœ“' if FREEZE_LAYERS['backbone'] else 'âœ—'}")
    print(f"   - FPN: {'âœ“' if FREEZE_LAYERS['fpn'] else 'âœ—'}")
    print(f"   - ProtoNet: {'âœ“' if FREEZE_LAYERS['proto_net'] else 'âœ—'}")
    print(f"   - Classification Layer: {'âœ— (Trainable)' if not FREEZE_LAYERS['prediction_layers']['class'] else 'âœ“'}")
    print("="*60 + "\n")

# ==================== éªŒè¯é…ç½® ====================

def validate_config():
    """éªŒè¯é…ç½®æ˜¯å¦æœ‰æ•ˆ"""
    errors = []

    # æ£€æŸ¥æ¯”ä¾‹å’Œæ˜¯å¦ä¸º1
    if abs(TRAIN_RATIO + VAL_RATIO + TEST_RATIO - 1.0) > 1e-6:
        errors.append(f"Dataset split ratios must sum to 1.0, got {TRAIN_RATIO + VAL_RATIO + TEST_RATIO}")

    # æ£€æŸ¥ç±»åˆ«æ•°é‡
    if NUM_CLASSES == 0:
        errors.append("NUM_CLASSES must be greater than 0")

    # æ£€æŸ¥batch size
    if BATCH_SIZE <= 0:
        errors.append("BATCH_SIZE must be greater than 0")

    # æ£€æŸ¥epochæ•°é‡
    if NUM_EPOCHS <= 0:
        errors.append("NUM_EPOCHS must be greater than 0")

    # æ£€æŸ¥å­¦ä¹ ç‡
    if LEARNING_RATE <= 0:
        errors.append("LEARNING_RATE must be greater than 0")

    if errors:
        print("\nâŒ Configuration Errors:")
        for error in errors:
            print(f"   - {error}")
        return False

    print("âœ“ Configuration validated successfully!")
    return True

# ==================== ç¯å¢ƒå˜é‡è¦†ç›– ====================

def load_env_overrides():
    """ä»ç¯å¢ƒå˜é‡åŠ è½½é…ç½®è¦†ç›–"""
    global BATCH_SIZE, NUM_EPOCHS, LEARNING_RATE, GPU_ID

    if 'BATCH_SIZE' in os.environ:
        BATCH_SIZE = int(os.environ['BATCH_SIZE'])

    if 'NUM_EPOCHS' in os.environ:
        NUM_EPOCHS = int(os.environ['NUM_EPOCHS'])

    if 'LEARNING_RATE' in os.environ:
        LEARNING_RATE = float(os.environ['LEARNING_RATE'])

    if 'GPU_ID' in os.environ:
        GPU_ID = int(os.environ['GPU_ID'])

# åˆå§‹åŒ–æ—¶è‡ªåŠ¨åŠ è½½ç¯å¢ƒå˜é‡
load_env_overrides()

if __name__ == "__main__":
    # æµ‹è¯•é…ç½®
    print_config()
    validate_config()
    create_dirs()
